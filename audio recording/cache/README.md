TranscriptFlow (Audio Transistor)
Show Image
Une application Streamlit pour extraire, transcrire, et analyser l'audio de vidÃ©os YouTube ou de fichiers locaux.
âœ¨ FonctionnalitÃ©s

Extraction audio depuis YouTube ou fichiers vidÃ©o locaux (MP4, MOV, AVI, etc.)
Transcription automatique avec plusieurs modÃ¨les Whisper (tiny Ã  large)
Traduction audio vers texte en anglais
Analyses GPT sur les transcriptions:

RÃ©sumÃ©s (bullet points, concis, dÃ©taillÃ©)
Extraction de mots-clÃ©s
Questions/RÃ©ponses sur le contenu
CrÃ©ation automatique de chapitres


SynthÃ¨se vocale (Text-to-Speech) avec plusieurs voix disponibles
Interface utilisateur intuitive avec mode clair/sombre
SystÃ¨me d'authentification multi-utilisateurs

ğŸ› ï¸ Technologies utilisÃ©es

Frontend: Streamlit
Extraction audio: yt-dlp, ffmpeg
Transcription: Whisper (local)
Analyses textuelles: API OpenAI (GPT-3.5, GPT-4)
Text-to-Speech: API OpenAI TTS
Authentification: streamlit-authenticator

ğŸ“‹ PrÃ©requis

Python 3.9+
FFmpeg installÃ© sur le systÃ¨me
Une clÃ© API OpenAI
Git (pour cloner le dÃ©pÃ´t)

ğŸš€ Installation

Cloner le dÃ©pÃ´t:
bashCopygit clone https://github.com/username/transcriptflow.git
cd transcriptflow

CrÃ©er un environnement virtuel:
bashCopypython -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows

Installer les dÃ©pendances:
bashCopypip install -r requirements.txt

Configurer les variables d'environnement:
CrÃ©ez un fichier .env Ã  la racine du projet:
CopyOPENAI_API_KEY=votre_clÃ©_api_openai

Lancer l'application:
bashCopystreamlit run app.py


ğŸ”‘ Authentification
Par dÃ©faut, l'application est configurÃ©e avec les utilisateurs suivants:

Admin:

Identifiant: admin
Mot de passe: admin
AccÃ¨s complet Ã  toutes les fonctionnalitÃ©s


Utilisateur test:

Identifiant: user1
Mot de passe: password
AccÃ¨s limitÃ© (visualisation uniquement)



Pour modifier les utilisateurs, Ã©ditez le fichier core/config.yaml.
ğŸ“Š Structure du projet
Copytranscriptflow/
â”œâ”€â”€ app.py                # Point d'entrÃ©e de l'application
â”œâ”€â”€ requirements.txt      # DÃ©pendances Python
â”œâ”€â”€ README.md             # Documentation
â”œâ”€â”€ .env                  # Variables d'environnement (Ã  crÃ©er)
â”œâ”€â”€ core/                 # FonctionnalitÃ©s principales
â”‚   â”œâ”€â”€ api_key_manager.py     # Gestion des clÃ©s API
â”‚   â”œâ”€â”€ audio_extractor.py     # Extraction audio
â”‚   â”œâ”€â”€ authentication.py      # SystÃ¨me d'authentification
â”‚   â”œâ”€â”€ error_handling.py      # Gestion des erreurs
â”‚   â”œâ”€â”€ gpt_processor.py       # Communication avec GPT
â”‚   â”œâ”€â”€ session_manager.py     # Gestion des sessions
â”‚   â”œâ”€â”€ transcription.py       # IntÃ©gration Whisper
â”‚   â””â”€â”€ utils.py               # Fonctions utilitaires
â”œâ”€â”€ my_page/             # Pages de l'interface
â”‚   â”œâ”€â”€ dashboard_1.py        # Dashboard
â”‚   â”œâ”€â”€ extraction_youtube_2.py  # Extraction YouTube
â”‚   â”œâ”€â”€ extract_video_3.py    # Extraction fichier vidÃ©o
â”‚   â”œâ”€â”€ transcription_4.py    # Transcription et analyse
â”‚   â”œâ”€â”€ text_to_audio.py      # Text-to-Speech
â”‚   â””â”€â”€ parametres.py         # Configuration
â”œâ”€â”€ image/               # Ressources graphiques
â””â”€â”€ tests/               # Tests unitaires
ğŸ“ Utilisation
1. Extraction d'audio
Depuis YouTube:

AccÃ©dez Ã  l'onglet "Extraction d'une vidÃ©o YouTube"
Collez l'URL YouTube
Cliquez sur "TÃ©lÃ©charger"

Depuis un fichier local:

AccÃ©dez Ã  l'onglet "Extraction d'un fichier vidÃ©o"
Uploadez votre fichier vidÃ©o
Cliquez sur "Extraire l'audio"

2. Transcription

AccÃ©dez Ã  l'onglet "Transcription"
Choisissez le modÃ¨le Whisper (base est un bon compromis vitesse/qualitÃ©)
Si nÃ©cessaire, cochez "Traduire en anglais"
Cliquez sur "Lancer la transcription"

3. Analyses GPT
Une fois la transcription terminÃ©e:

RÃ©sumÃ©: Choisissez le style et cliquez sur "GÃ©nÃ©rer un rÃ©sumÃ©"
Mots-clÃ©s: Cliquez sur "Extraire les mots-clÃ©s"
Q/R: Posez une question sur le contenu et obtenez une rÃ©ponse
Chapitres: Divisez automatiquement le contenu en chapitres

4. Text-to-Speech

AccÃ©dez Ã  l'onglet "Text to Audio"
Entrez ou collez le texte Ã  convertir en audio
Choisissez le modÃ¨le et la voix
Cliquez sur "GÃ©nÃ©rer l'audio"

ğŸ“ˆ Performances
Les performances dÃ©pendent du matÃ©riel utilisÃ© et des modÃ¨les sÃ©lectionnÃ©s:

Transcription:

ModÃ¨le tiny: ~32x temps rÃ©el (trÃ¨s rapide, moins prÃ©cis)
ModÃ¨le base: ~16x temps rÃ©el (bon Ã©quilibre)
ModÃ¨le large: ~1x temps rÃ©el (plus lent, trÃ¨s prÃ©cis)


Analyses GPT:

Temps de rÃ©ponse: 2-10 secondes selon la longueur du texte
CoÃ»t approximatif: ~$0.02 par analyse (GPT-3.5) / ~$0.20 (GPT-4)


Text-to-Speech:

Temps de gÃ©nÃ©ration: ~5 secondes pour 200 mots
CoÃ»t approximatif: ~$0.015 par 1000 caractÃ¨res (tts-1)



ğŸ¤ Contribution
Les contributions sont les bienvenues! Voici comment procÃ©der:

Forkez le dÃ©pÃ´t
CrÃ©ez une branche pour votre fonctionnalitÃ© (git checkout -b feature/amazing-feature)
Committez vos changements (git commit -m 'Add amazing feature')
Poussez vers la branche (git push origin feature/amazing-feature)
Ouvrez une Pull Request

ğŸ“œ Licence
Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.
ğŸ™ Remerciements

Streamlit pour l'interface
Whisper pour la transcription
OpenAI pour les API GPT et TTS
yt-dlp pour l'extraction YouTube