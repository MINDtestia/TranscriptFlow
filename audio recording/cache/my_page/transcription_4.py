import streamlit as st
import logging
import tempfile
import os
from typing import Optional, Dict, Any, List, Tuple
import time
import psutil

from core.transcription import transcribe_or_translate_locally, request_transcription
from core.gpt_processor import summarize_text, extract_keywords, ask_question_about_text
from core.utils import create_chapters_from_segments, export_text_file
from core.error_handling import handle_error, ErrorType, safe_execute
from core.session_manager import get_session_value, set_session_value
from core.api_key_manager import api_key_manager
from core.storage_manager import storage_manager
from core.database import Transcription, get_db
from core.task_queue import celery_app
from celery.result import AsyncResult

# Types personnalis√©s pour la clart√©
SegmentType = Dict[str, Any]
TranscriptionResult = Dict[str, Any]

# Liste compl√®te des mod√®les disponibles
GPT_MODELS = {
    "gpt-3.5-turbo": {"name": "GPT-3.5", "cost": "$0.01-0.05", "speed": "Rapide"},
    "gpt-4o": {"name": "GPT-4o", "cost": "$0.05-0.20", "speed": "Mod√©r√©"},
    "gpt-4o-mini": {"name": "GPT-4o Mini", "cost": "$0.02-0.10", "speed": "Mod√©r√©"},
    "gpt-4": {"name": "GPT-4", "cost": "$0.10-0.50", "speed": "Lent"}
}

# Fonctions de transcription avec cache
@st.cache_data(show_spinner=False, ttl=3600)
def cached_transcribe(
        file_path: str,
        whisper_model: str,
        translate: bool
) -> TranscriptionResult:
    """
    Cache le r√©sultat de la transcription pour √©viter de refaire le travail.

    Args:
        file_path: Chemin du fichier audio
        whisper_model: Mod√®le Whisper √† utiliser
        translate: Si True, traduit plut√¥t que transcrire

    Returns:
        R√©sultat de la transcription
    """
    return transcribe_or_translate_locally(file_path, whisper_model, translate)


def check_transcription_status(task_id):
    """V√©rifie le statut d'une t√¢che de transcription"""
    task = AsyncResult(task_id, app=celery_app)
    return task.status, task.result


def process_transcription_sync(
        audio_data: bytes,
        whisper_model: str,
        translate: bool = False
) -> Tuple[bool, str]:
    """
    Traite la transcription d'un fichier audio avec une barre de progression.
    Version synchrone (pour petits fichiers ou compatibilit√©)
    """
    start_time = time.time()
    if not audio_data:
        return False, "Aucun fichier audio fourni."

    try:
        # Cr√©er la barre de progression
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("Pr√©paration du fichier...")

        # √âtape 1: Cr√©er un fichier temporaire
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            tmp_path = tmp.name
            tmp.write(audio_data)

        # V√©rifier que le fichier existe et a la bonne taille
        if not os.path.exists(tmp_path) or os.path.getsize(tmp_path) == 0:
            return False, "Erreur lors de la cr√©ation du fichier temporaire."

        logging.info(f"Fichier temporaire cr√©√©: {tmp_path} ({os.path.getsize(tmp_path)} bytes)")

        progress_bar.progress(0.1)
        status_text.text("Fichier pr√™t. Chargement du mod√®le Whisper...")

        # √âtape 2: Lancer la transcription
        def progress_callback(progress, message):
            progress_bar.progress(0.1 + progress * 0.8)
            status_text.text(message)

        # Utiliser la version non-cach√©e pour les mod√®les lourds
        if whisper_model in ["medium", "large"]:
            result = transcribe_or_translate_locally(tmp_path, whisper_model, translate, progress_callback)
        else:
            # Utiliser la version cach√©e pour les mod√®les l√©gers (tiny, base, small)
            result = cached_transcribe(tmp_path, whisper_model, translate)

        # √âtape 3: Traiter le r√©sultat
        progress_bar.progress(0.9)
        status_text.text("Finalisation...")

        # Nettoyage du fichier temporaire
        try:
            os.remove(tmp_path)
        except Exception as e:
            logging.warning(f"Impossible de supprimer le fichier temporaire: {tmp_path}, Erreur: {str(e)}")

        # V√©rifier les erreurs
        if result.get("error"):
            progress_bar.progress(1.0)
            status_text.text(f"Erreur: {result.get('error')}")
            return False, result.get("error")

        # Sauvegarder dans le stockage et la base de donn√©es
        # Sauvegarder l'audio (uniquement si nous voulons le conserver)
        filename = f"audio_{int(time.time())}.wav"
        audio_path = storage_manager.save_audio_file(
            st.session_state["user_id"],
            audio_data,
            filename
        )

        if not audio_path:
            logging.warning("Impossible de sauvegarder l'audio, mais la transcription continue")
            # On continue m√™me si l'audio n'est pas sauvegard√©

        # Sauvegarder la transcription
        transcription_filename = f"transcription_{int(time.time())}.txt"
        transcription_path = storage_manager.save_transcription(
            st.session_state["user_id"],
            result["text"],
            transcription_filename
        )

        if not transcription_path:
            logging.warning("Impossible de sauvegarder la transcription dans le stockage, mais on continue")
            # On continue m√™me si la transcription n'est pas sauvegard√©e dans le stockage

        # Enregistrer dans la base de donn√©es
        try:
            db = next(get_db())

            new_transcription = Transcription(
                user_id=st.session_state["user_id"],
                filename=filename,
                duration=time.time() - start_time,  # Dur√©e r√©elle du traitement
                model_used=whisper_model,
                text=result["text"]
            )

            db.add(new_transcription)
            db.commit()
        except Exception as e:
            logging.error(f"Erreur lors de l'enregistrement en base de donn√©es: {str(e)}")
            # On continue quand m√™me car on a la transcription

        # Stockage des r√©sultats dans la session
        st.session_state["transcribed_text"] = result["text"]
        st.session_state["segments"] = result["segments"]
        st.session_state["detected_language"] = result.get("language", "")
        st.session_state["transcription_completed"] = True
        st.session_state["last_transcription_time"] = int(time.time())

        # Terminer la barre de progression
        progress_bar.progress(1.0)
        status_text.text("Transcription termin√©e!")
        time.sleep(0.5)  # Laisser le temps de voir le message

        # Forcer le rafra√Æchissement pour afficher la transcription
        st.markdown(
            """
            <script>
            setTimeout(function() {
                window.location.reload();
            }, 1000);
            </script>
            """,
            unsafe_allow_html=True
        )

        from core.session_manager import log_user_activity

        duration_seconds = time.time() - start_time
        log_user_activity(
            st.session_state["user_id"],
            "transcription",
            f"Mod√®le: {whisper_model}, Dur√©e: {duration_seconds :.1f}s"
        )

        # Essayer de forcer le rerun de Streamlit
        st.rerun()

        return True, "Transcription termin√©e avec succ√®s!"

    except Exception as e:
        logging.error(f"Exception dans process_transcription_sync: {str(e)}")
        return False, f"Erreur lors de la transcription: {str(e)}"



def process_transcription_async(audio_data, whisper_model, translate=False):
    """
    Version asynchrone de la transcription utilisant la file d'attente
    """
    if not audio_data:
        return False, "Aucun fichier audio fourni."

    try:
        # Cr√©er un fichier temporaire pour sauvegarder l'audio
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            tmp_path = tmp.name
            tmp.write(audio_data)

        # V√©rifier que le fichier existe
        if not os.path.exists(tmp_path) or os.path.getsize(tmp_path) == 0:
            return False, "Erreur lors de la cr√©ation du fichier temporaire."

        logging.info(
            f"Fichier temporaire pour traitement asynchrone cr√©√©: {tmp_path} ({os.path.getsize(tmp_path)} bytes)")

        # Sauvegarder l'audio
        filename = f"audio_{int(time.time())}.wav"
        audio_path = storage_manager.save_audio_file(
            st.session_state["user_id"],
            audio_data,
            filename
        )

        if not audio_path:
            return False, "Erreur lors de la sauvegarde du fichier audio."

        logging.info(f"Audio sauvegard√© avec succ√®s: {audio_path}")

        # Si nous sommes ici, c'est que le stockage a fonctionn√©. On peut lancer la transcription
        try:
            # Demander la transcription asynchrone
            task_id = request_transcription(
                audio_path,
                st.session_state["user_id"],
                filename,
                whisper_model,
                translate
            )

            if not task_id:
                return False, "Erreur lors du lancement de la t√¢che de transcription."

            # Stocker l'ID de la t√¢che dans la session
            st.session_state["transcription_task_id"] = task_id
            logging.info(f"T√¢che de transcription lanc√©e avec ID: {task_id}")

            return True, "Transcription lanc√©e en arri√®re-plan. Vous pouvez suivre l'avancement ici."
        except Exception as e:
            logging.error(f"Erreur lors du lancement de la transcription: {str(e)}")
            return False, f"Erreur lors du lancement de la transcription: {str(e)}"

    except Exception as e:
        logging.error(f"Exception dans process_transcription_async: {str(e)}")
        return False, f"Erreur lors du traitement de la transcription: {str(e)}"


# [Les fonctions pour les analyses GPT restent inchang√©es]
def run_gpt_summary(api_key, style: str = "bullet", model="gpt-3.5-turbo", temperature=0.7):
    """G√©n√®re un r√©sum√© du texte transcrit"""
    text = get_session_value("transcribed_text", "")

    if not text:
        st.warning("Aucun texte √† r√©sumer. Veuillez d'abord faire une transcription.")
        return False

    if not api_key:
        st.error("Cl√© API OpenAI requise pour cette fonctionnalit√©.")
        return False

    try:
        # Nettoyer le texte des caract√®res probl√©matiques
        text = text.encode('utf-8', errors='replace').decode('utf-8')

        with st.spinner("G√©n√©ration du r√©sum√© en cours..."):
            summary = summarize_text(
                text=text,
                api_key=api_key,
                gpt_model=model,
                temperature=temperature,
                style=style
            )

        # V√©rifier si le r√©sum√© contient une erreur
        if summary.startswith("Erreur"):
            st.error(summary)
            return False

        set_session_value("summary_result", summary)
        return True
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration du r√©sum√©: {str(e)}")
        logging.error(f"Exception dans run_gpt_summary: {str(e)}")
        return False

def optimize_whisper_for_limited_ram(model_name="base"):
    """Configure Whisper pour fonctionner avec une RAM limit√©e"""
    # Limiter l'utilisation de la m√©moire pour les mod√®les whisper
    os.environ["WHISPER_FORCE_CPU"] = "1"  # Force CPU pour une meilleure compatibilit√©
    os.environ["OMP_NUM_THREADS"] = "2"  # Limite les threads OpenMP

    # Recommandation bas√©e sur la taille du mod√®le
    recommended_model = model_name
    if model_name == "large" and psutil.virtual_memory().available < 8 * 1024 * 1024 * 1024:  # 8GB
        logging.warning("RAM insuffisante pour le mod√®le large, passage automatique √† medium")
        recommended_model = "medium"
    elif model_name == "medium" and psutil.virtual_memory().available < 4 * 1024 * 1024 * 1024:  # 4GB
        logging.warning("RAM insuffisante pour le mod√®le medium, passage automatique √† small")
        recommended_model = "small"

    return recommended_model

def run_gpt_keywords(api_key: str, model: str = "gpt-3.5-turbo") -> bool:
    """
    Extrait les mots-cl√©s du texte transcrit via GPT.

    Args:
        api_key: Cl√© API OpenAI
        model: Mod√®le GPT √† utiliser

    Returns:
        True si succ√®s, False sinon
    """
    text = get_session_value("transcribed_text", "")
    if not text:
        st.warning("Aucun texte pour extraire des mots-cl√©s. Veuillez d'abord faire une transcription.")
        return False

    if not api_key:
        st.warning("Cl√© API OpenAI requise pour cette fonctionnalit√©.")
        return False

    try:
        with st.spinner("Extraction des mots-cl√©s en cours..."):
            keywords = extract_keywords(text, api_key, model=model)

        set_session_value("keywords_result", keywords)
        return True

    except Exception as e:
        handle_error(e, ErrorType.API_ERROR,
                     "Erreur lors de l'extraction des mots-cl√©s.")
        return False


def run_gpt_question(question: str, api_key: str, model: str = "gpt-3.5-turbo") -> bool:
    """
    Pose une question au texte transcrit via GPT.

    Args:
        question: Question √† poser
        api_key: Cl√© API OpenAI
        model: Mod√®le GPT √† utiliser

    Returns:
        True si succ√®s, False sinon
    """
    if not api_key:
        st.error("Cl√© API OpenAI manquante. Veuillez configurer votre cl√© API dans le menu 'API Cl√©s'.")
        st.warning("Vous pouvez obtenir une cl√© API sur openai.com/api")
        return False

    text = get_session_value("transcribed_text", "")
    if not text:
        st.warning("Aucun texte pour poser une question. Veuillez d'abord faire une transcription.")
        return False

    if not question.strip():
        st.warning("Veuillez saisir une question.")
        return False

    if not api_key:
        st.warning("Cl√© API OpenAI requise pour cette fonctionnalit√©.")
        return False

    try:
        with st.spinner("Traitement de la question en cours..."):
            answer = ask_question_about_text(text, question, api_key, model=model)

        set_session_value("answer_result", answer)
        return True

    except Exception as e:
        handle_error(e, ErrorType.API_ERROR,
                     "Erreur lors du traitement de la question.")
        return False


def create_text_chapters(chunk_duration: float = 60.0) -> bool:
    """
    Cr√©e des chapitres √† partir des segments de transcription.

    Args:
        chunk_duration: Dur√©e en secondes pour chaque chapitre

    Returns:
        True si succ√®s, False sinon
    """
    segments = get_session_value("segments", [])
    if not segments:
        st.warning("Aucun segment disponible. Veuillez faire une transcription avant.")
        return False

    try:
        with st.spinner("Cr√©ation des chapitres en cours..."):
            chapters = create_chapters_from_segments(segments, chunk_duration=chunk_duration)
            chapter_text = "\n".join(chapters)

        set_session_value("chapters_result", chapter_text)
        return True

    except Exception as e:
        handle_error(e, ErrorType.PROCESSING_ERROR,
                     "Erreur lors de la cr√©ation des chapitres.")
        return False


def export_text_to_file(text: str, filename: str) -> bool:
    """
    Exporte du texte vers un fichier et propose le t√©l√©chargement.

    Args:
        text: Texte √† exporter
        filename: Nom du fichier

    Returns:
        True si succ√®s, False sinon
    """
    if not text.strip():
        st.warning("Aucun texte √† exporter.")
        return False

    try:
        export_folder = get_session_value("export_folder", "")
        path = export_text_file(text, export_folder, filename)

        # Propose le t√©l√©chargement direct
        st.download_button(
            label="T√©l√©charger le fichier",
            data=text.encode("utf-8"),
            file_name=filename,
            mime="text/plain"
        )

        return True

    except Exception as e:
        handle_error(e, ErrorType.FILE_ERROR,
                     "Erreur lors de l'export du fichier.")
        return False

def model_format_func(model_id):
    """Formate l'affichage des mod√®les dans le selectbox"""
    model_info = GPT_MODELS.get(model_id, {})
    return f"{model_info.get('name', model_id)} - {model_info.get('speed', '')}"


def afficher_page_4():
    st.title("Transcription / Traduction")

    # D√©tection mobile
    is_mobile = st.session_state.get("is_mobile", False)

    # V√©rifier si l'audio a √©t√© pass√© depuis l'extraction YouTube
    audio_data = get_session_value("audio_bytes_for_transcription")
    if audio_data:
        logging.info(f"Audio trouv√© dans la session: {len(audio_data)} bytes")
        st.success("Audio charg√© depuis l'extraction pr√©c√©dente!")
        st.audio(audio_data, format="audio/wav")
    else:
        logging.warning("Aucun audio trouv√© dans la session")

    # Importer les v√©rifications des quotas du plan
    from core.plan_manager import PlanManager

    # R√©cup√©rer la cl√© API OpenAI
    openai_api_key = api_key_manager.get_key("openai")

    # Interface principale - tabs adapt√©s pour mobile/desktop
    tabs = st.tabs(["Transcription", "R√©sum√©", "Mots-cl√©s", "Q/R", "Chapitres"] if is_mobile else
                   ["Transcription", "R√©sum√©", "Mots-cl√©s", "Questions/R√©ponses", "Chapitres"])

    # Tab 1: Transcription
    with tabs[0]:
        if is_mobile:
            # Version mobile: empil√©e verticalement
            # Options de transcription
            st.subheader("Options")

            whisper_model = st.selectbox(
                "Mod√®le Whisper",
                ["tiny", "base", "small", "medium"],
                help="Plus le mod√®le est grand, plus la transcription est pr√©cise mais lente."
            )

            # V√©rification de l'acc√®s au mod√®le
            if whisper_model in ["medium"]:
                st.warning(
                    f"‚ö†Ô∏è Le mod√®le {whisper_model} est tr√®s gourmand en ressources. Sur votre mat√©riel, la transcription pourrait prendre 10-15 minutes ou plus pour 1 minute d'audio.")

            translate_checkbox = st.checkbox(
                "Traduire en anglais",
                value=False,
                help="Traduit l'audio en anglais quelle que soit la langue d'origine."
            )

            use_async = st.checkbox(
                "Traitement asynchrone",
                value=True,
                help="Recommand√© pour les fichiers longs."
            )

            # Source audio
            st.subheader("Source audio")

            # Options de source audio
            audio_data = get_session_value("audio_bytes_for_transcription")
            if audio_data:
                st.success("Audio charg√© depuis l'extraction pr√©c√©dente.")
                st.audio(audio_data, format="audio/wav")

            audio_file = st.file_uploader(
                "Charger un fichier audio",
                type=["wav", "mp3", "m4a", "ogg"]
            )

            if audio_file:
                file_size_mb = audio_file.size / (1024 * 1024)
                if "user_id" in st.session_state:
                    if not PlanManager.check_file_size_limit(st.session_state["user_id"], file_size_mb):
                        st.warning(f"Ce fichier ({file_size_mb:.1f} MB) d√©passe la limite de votre forfait.")
                audio_data = audio_file.read()
                st.audio(audio_data, format=f"audio/{audio_file.type.split('/')[1]}")
                st.info(f"Taille: {file_size_mb:.1f} MB")

            # Bouton de transcription
            transcribe_button = st.button(
                "Lancer la transcription",
                disabled=audio_data is None and audio_file is None,
                use_container_width=True
            )

            # Affichage des r√©sultats
            st.subheader("Texte transcrit")

            transcribed_text = get_session_value("transcribed_text", "")
            detected_language = get_session_value("detected_language", "")

            if detected_language:
                st.info(f"Langue d√©tect√©e: {detected_language}")

            text_area = st.text_area(
                "Transcription",
                value=transcribed_text,
                height=250,
                key="transcription_textarea"
            )

            # Si modifi√©, mettre √† jour
            if text_area != transcribed_text:
                set_session_value("transcribed_text", text_area)

            # Options d'export simplifi√©es pour mobile
            if transcribed_text:
                if st.button("Exporter la transcription (.txt)", use_container_width=True):
                    if export_text_to_file(transcribed_text, "transcription.txt"):
                        st.success("Transcription export√©e!")

        else:
            # Version desktop: colonnes c√¥te √† c√¥te
            col1, col2 = st.columns([1, 1])

            with col1:
                # Options de transcription
                st.subheader("Options")

                whisper_model = st.selectbox(
                    "Mod√®le Whisper",
                    ["tiny", "base", "small", "medium", "large"],
                    help="Plus le mod√®le est grand, plus la transcription est pr√©cise mais lente."
                )

                # V√©rification de l'acc√®s au mod√®le
                if whisper_model not in ["tiny", "base"] and "user_id" in st.session_state:
                    if not PlanManager.check_model_access(st.session_state["user_id"], whisper_model):
                        st.warning(
                            f"Note: Le mod√®le {whisper_model} n√©cessite un forfait sup√©rieur. La transcription peut √©chouer.")

                translate_checkbox = st.checkbox(
                    "Traduire en anglais (au lieu de transcrire)",
                    value=False,
                    help="Traduit l'audio en anglais quelle que soit la langue d'origine."
                )
                """
                use_async = st.checkbox(
                    "Utiliser le traitement asynchrone",
                    value=True,
                    help="Recommand√© pour les fichiers longs. La transcription s'ex√©cutera en arri√®re-plan."
                )
                """
                st.warning("Transcription asynchrone d√©sactiv√©e en mode d√©veloppement (Redis non disponible)")
                use_async = st.checkbox(
                    "Utiliser le traitement asynchrone (d√©sactiv√©)",
                    value=False,
                    disabled=True,
                    help="N√©cessite Redis en mode production."
                )

                # Source audio
                st.subheader("Source audio")

                # Option 1: Fichier depuis session (pr√©c√©demment t√©l√©charg√©)
                audio_data = get_session_value("audio_bytes_for_transcription")
                if audio_data:
                    st.success("Fichier audio charg√© depuis l'extraction pr√©c√©dente.")
                    st.audio(audio_data, format="audio/wav")

                # Option 2: Upload direct
                audio_file = st.file_uploader(
                    "Ou chargez un fichier audio",
                    type=["wav", "mp3", "m4a", "ogg"],
                    help="Formats support√©s: WAV, MP3, M4A, OGG"
                )

                if audio_file:
                    file_size_mb = audio_file.size / (1024 * 1024)

                    # V√©rifier la taille du fichier
                    if "user_id" in st.session_state:
                        if not PlanManager.check_file_size_limit(st.session_state["user_id"], file_size_mb):
                            st.warning(
                                f"Ce fichier ({file_size_mb:.1f} MB) d√©passe la limite de votre forfait. Veuillez passer √† un forfait sup√©rieur.")

                    audio_data = audio_file.read()
                    st.audio(audio_data, format=f"audio/{audio_file.type.split('/')[1]}")
                    st.info(f"Taille du fichier: {file_size_mb:.1f} MB")

                # Bouton de transcription
                transcribe_button = st.button(
                    "Lancer la transcription",
                    disabled=audio_data is None and audio_file is None,
                    use_container_width=True
                )

            with col2:
                # Affichage des r√©sultats
                st.subheader("Texte transcrit")

                transcribed_text = get_session_value("transcribed_text", "")
                detected_language = get_session_value("detected_language", "")

                if detected_language:
                    st.info(f"Langue d√©tect√©e: {detected_language}")

                text_area = st.text_area(
                    "Transcription",
                    value=transcribed_text,
                    height=350,
                    key="transcription_textarea"
                )

                # Si modifi√©, mettre √† jour
                if text_area != transcribed_text:
                    set_session_value("transcribed_text", text_area)

                # Options d'export
                if transcribed_text:
                    st.subheader("Exporter")
                    export_folder = st.text_input(
                        "Dossier d'export (optionnel)",
                        placeholder="Ex: /home/user/documents"
                    )
                    set_session_value("export_folder", export_folder)

                    if st.button("Exporter la transcription (.txt)"):
                        if export_text_to_file(transcribed_text, "transcription.txt"):
                            st.success("Transcription export√©e avec succ√®s!")

        # Traitement du bouton de transcription (identique pour les deux layouts)
        if transcribe_button:
            # V√©rifier les quotas
            if "user_id" in st.session_state:
                if not PlanManager.check_transcription_quota(st.session_state["user_id"]):
                    st.error("Vous avez atteint votre quota de transcription pour ce mois.")
                else:
                    # R√©cup√©rer l'audio √† transcrire, en priorit√© √† partir de audio_data
                    data_to_transcribe = None

                    # D'abord v√©rifier si on a de l'audio en session
                    if audio_data:
                        data_to_transcribe = audio_data
                        logging.info(f"Utilisation de l'audio depuis la session: {len(data_to_transcribe)} bytes")
                    # Sinon, utiliser le fichier upload√© s'il existe
                    elif audio_file:
                        data_to_transcribe = audio_file.read()
                        logging.info(
                            f"Utilisation de l'audio depuis le fichier upload√©: {len(data_to_transcribe)} bytes")

                    if data_to_transcribe:
                        # Continuer avec le traitement comme avant...
                        if use_async:
                            success, message = process_transcription_async(
                                data_to_transcribe,
                                whisper_model,
                                translate_checkbox
                            )
                        else:
                            success, message = process_transcription_sync(
                                data_to_transcribe,
                                whisper_model,
                                translate_checkbox
                            )

                        if success:
                            st.success(message)
                            # Si transcription r√©ussie, effacer l'audio temporaire de la session
                            set_session_value("audio_bytes_for_transcription", None)
                        else:
                            st.error(message)
                    else:
                        st.error(
                            "Aucun audio √† transcrire. Veuillez charger un fichier audio ou extraire depuis YouTube.")
            else:
                st.error("Erreur de session. Veuillez vous reconnecter.")

        # V√©rifier le statut des t√¢ches en cours
        if "transcription_task_id" in st.session_state:
            task_id = st.session_state["transcription_task_id"]
            status, result = check_transcription_status(task_id)

            status_container = st.container()

            if status == "PENDING":
                status_container.warning("Transcription en attente de traitement...")
            elif status == "STARTED":
                status_container.info("Transcription en cours...")
            elif status == "SUCCESS":
                status_container.success("Transcription termin√©e avec succ√®s!")
                # Mettre √† jour la session avec le r√©sultat
                set_session_value("transcribed_text", result["text"])
                set_session_value("detected_language", result.get("language", ""))
                # Supprimer l'ID de t√¢che de la session
                del st.session_state["transcription_task_id"]
                # Forcer le rafra√Æchissement
                st.rerun()
            elif status == "FAILURE":
                status_container.error("La transcription a √©chou√©. Veuillez r√©essayer.")
                if st.button("Effacer la t√¢che"):
                    del st.session_state["transcription_task_id"]
                    st.rerun()

    # Impl√©mentation des autres onglets... (R√©sum√©, Mots-cl√©s, Questions/R√©ponses, Chapitres)
    # [Inclure le code existant pour les autres onglets ici]
    with tabs[1]:  # Onglet R√©sum√©
        st.subheader("üí° R√©sum√© de la transcription")

        # V√©rifier si une transcription existe
        transcribed_text = get_session_value("transcribed_text", "")
        if not transcribed_text:
            st.warning("‚ö†Ô∏è Aucune transcription disponible. Veuillez d'abord effectuer une transcription.")
            return

        # V√©rifier la longueur minimale du texte
        if len(transcribed_text.split()) < 20:
            st.warning(
                "‚ö†Ô∏è Le texte transcrit est trop court pour g√©n√©rer un r√©sum√© pertinent (minimum 20 mots requis).")
            return

        # V√©rifier si une cl√© API est configur√©e
        api_key = api_key_manager.get_key("openai")
        if not api_key:
            st.error("‚ùå Cl√© API OpenAI manquante. Configurez votre cl√© API dans le menu 'API Cl√©s'.")
            st.info("‚ÑπÔ∏è Obtenez une cl√© API sur https://platform.openai.com/api-keys")
            with st.expander("Comment configurer une cl√© API OpenAI"):
                st.markdown("""
                   1. Cr√©ez un compte sur [OpenAI](https://platform.openai.com/)
                   2. Allez dans "API Keys" et cliquez sur "Create new secret key"
                   3. Copiez la cl√© g√©n√©r√©e
                   4. Collez-la dans le menu "API Cl√©s" de cette application
                   """)
            return

        # Afficher les options de r√©sum√© dans une colonne
        col1, col2 = st.columns([3, 1])

        with col1:
            # Choix du mode de prompt
            mode = st.radio(
                "S√©lectionnez le mode de prompt",
                ["Prompt personnalis√©", "Utiliser les √©v√®nements ci-dessus"]
            )

            if mode == "Prompt personnalis√©":
                # Saisie d'un prompt personnalis√©
                summary_style = st.text_area(
                    "Entrez votre prompt personnalis√©",
                    key="custom_prompt",
                    height=100
                )
            else:
                # S√©lection du style de r√©sum√©
                summary_style = st.radio(
                    "Style de r√©sum√©",
                    ["bullet", "concise", "detailed"],
                    horizontal=True,
                    format_func=lambda x: {
                        "bullet": "Liste √† puces",
                        "concise": "Concis (quelques phrases)",
                        "detailed": "D√©taill√© (paragraphes)"
                    }.get(x, x)
                )

            # S√©lection du mod√®le GPT
            gpt_model = st.selectbox(
                "Mod√®le GPT",
                options=list(GPT_MODELS.keys()),
                index=0,
                format_func=model_format_func,
                help="S√©lectionnez le mod√®le GPT √† utiliser"
            )

        with col2:
            st.write("")
            st.write("")
            generate_button = st.button(
                f"G√©n√©rer le r√©sum√©",
                type="primary",
                use_container_width=True
            )

            # Information sur le co√ªt
            selected_model_info = GPT_MODELS.get(gpt_model, {})
            st.caption(f"Co√ªt estim√©: {selected_model_info.get('cost', 'Inconnu')}")

        # Afficher la barre de s√©paration
        st.divider()

        # R√©sultat existant ou traitement de la g√©n√©ration
        summary_result = get_session_value("summary_result", "")

        if generate_button:
            with st.spinner("G√©n√©ration du r√©sum√© en cours..."):
                if run_gpt_summary(api_key, summary_style, gpt_model):
                    summary_result = get_session_value("summary_result", "")
                    st.success("‚úÖ R√©sum√© g√©n√©r√© avec succ√®s!")

        # Affichage du r√©sultat
        if summary_result:
            # Titre dynamique selon le style
            summary_title = {
                "bullet": "R√©sum√© en points cl√©s",
                "concise": "R√©sum√© concis",
                "detailed": "R√©sum√© d√©taill√©"
            }.get(summary_style, "R√©sum√©")

            # Affichage du r√©sum√©
            st.subheader(summary_title)
            st.markdown(summary_result)

            # Options pour t√©l√©charger ou copier
            col1, col2 = st.columns(2)
            with col1:
                st.download_button(
                    label="T√©l√©charger en TXT",
                    data=summary_result,
                    file_name=f"resume_{int(time.time())}.txt",
                    mime="text/plain",
                    use_container_width=True
                )

            with col2:
                if st.button("Copier dans le presse-papier", use_container_width=True):
                    st.code(summary_result)
                    st.info("S√©lectionnez et copiez le texte ci-dessus")

    with tabs[2]:  # Onglet Mots-cl√©s
        st.subheader("üîë Extraction de mots-cl√©s")

        # V√©rifier si une transcription existe
        transcribed_text = get_session_value("transcribed_text", "")
        if not transcribed_text:
            st.warning("‚ö†Ô∏è Aucune transcription disponible. Veuillez d'abord effectuer une transcription.")
            return

        # V√©rifier la longueur minimale du texte
        if len(transcribed_text.split()) < 20:
            st.warning(
                "‚ö†Ô∏è Le texte transcrit est trop court pour extraire des mots-cl√©s pertinents (minimum 20 mots requis).")
            return

        # V√©rifier si une cl√© API est configur√©e
        api_key = api_key_manager.get_key("openai")
        if not api_key:
            st.error("‚ùå Cl√© API OpenAI manquante. Configurez votre cl√© API dans le menu 'API Cl√©s'.")
            st.info("‚ÑπÔ∏è Obtenez une cl√© API sur https://platform.openai.com/api-keys")
            return

        # Options d'extraction
        col1, col2 = st.columns([3, 1])

        with col1:
            gpt_model = st.selectbox(
                "Mod√®le GPT",
                options=list(GPT_MODELS.keys()),
                index=0,
                format_func=model_format_func,
                help="S√©lectionnez le mod√®le GPT √† utiliser",
                key = "model_choose"
            )

        with col2:
            st.write("")
            st.write("")
            extract_button = st.button(
                "Extraire les mots-cl√©s",
                type="primary",
                use_container_width=True
            )

            # Information sur le co√ªt
            selected_model_info = GPT_MODELS.get(gpt_model, {})
            st.caption(f"Co√ªt estim√©: {selected_model_info.get('cost', 'Inconnu')}")

        # Afficher la barre de s√©paration
        st.divider()

        # R√©sultat existant ou traitement de l'extraction
        keywords_result = get_session_value("keywords_result", "")

        if extract_button:
            with st.spinner("Extraction des mots-cl√©s en cours..."):
                if run_gpt_keywords(api_key, gpt_model):
                    keywords_result = get_session_value("keywords_result", "")
                    st.success("‚úÖ Mots-cl√©s extraits avec succ√®s!")

        # Affichage du r√©sultat
        if keywords_result:
            st.subheader("Mots-cl√©s extraits")

            # Traitement des mots-cl√©s pour un affichage plus attrayant
            keywords_list = [k.strip() for k in keywords_result.split(',')]

            # Affichage sous forme de badges
            html_tags = ""
            for keyword in keywords_list:
                if keyword:
                    html_tags += f'<span style="background-color:#1E90FF; color:white; padding:5px 10px; margin:5px; border-radius:15px; display:inline-block;">{keyword}</span>'

            st.markdown(f"<div style='margin:10px 0;'>{html_tags}</div>", unsafe_allow_html=True)

            # Version texte pour copier ou t√©l√©charger
            st.markdown("##### Liste des mots-cl√©s")
            st.code(keywords_result)

            col1, col2 = st.columns(2)
            with col1:
                st.download_button(
                    label="T√©l√©charger en TXT",
                    data=keywords_result,
                    file_name=f"mots_cles_{int(time.time())}.txt",
                    mime="text/plain",
                    use_container_width=True
                )

    with tabs[3]:  # Onglet Questions/R√©ponses
        st.subheader("‚ùì Questions sur le contenu")

        # V√©rifier si une transcription existe
        transcribed_text = get_session_value("transcribed_text", "")
        if not transcribed_text:
            st.warning("‚ö†Ô∏è Aucune transcription disponible. Veuillez d'abord effectuer une transcription.")
            return

        # V√©rifier la longueur minimale du texte
        if len(transcribed_text.split()) < 20:
            st.warning(
                "‚ö†Ô∏è Le texte transcrit est trop court pour poser des questions pertinentes (minimum 20 mots requis).")
            return

        # V√©rifier si une cl√© API est configur√©e
        api_key = api_key_manager.get_key("openai")
        if not api_key:
            st.error("‚ùå Cl√© API OpenAI manquante. Configurez votre cl√© API dans le menu 'API Cl√©s'.")
            st.info("‚ÑπÔ∏è Obtenez une cl√© API sur https://platform.openai.com/api-keys")
            return

        # S√©lection du mod√®le et zone de question
        col1, col2 = st.columns([3, 1])

        with col1:
            # Question
            question_input = st.text_area(
                "Posez une question sur le contenu transcrit",
                placeholder="Exemple: Quels sont les points principaux abord√©s dans cette transcription?",
                height=80
            )

        with col2:
            # Mod√®le
            gpt_model = st.selectbox(
                "Mod√®le GPT",
                options=list(GPT_MODELS.keys()),
                index=0,
                format_func=model_format_func,
                help="S√©lectionnez le mod√®le GPT √† utiliser",
                key="model_choose_1"
            )

            # Bouton de g√©n√©ration
            ask_button = st.button(
                "Poser la question",
                type="primary",
                disabled=not question_input.strip(),
                use_container_width=True
            )

            # Information sur le co√ªt
            selected_model_info = GPT_MODELS.get(gpt_model, {})
            st.caption(f"Co√ªt estim√©: {selected_model_info.get('cost', 'Inconnu')}")

        # Afficher la barre de s√©paration
        st.divider()

        # R√©sultat existant ou traitement de la question
        answer_result = get_session_value("answer_result", "")
        last_question = get_session_value("last_question", "")

        if ask_button and question_input.strip():
            with st.spinner("Analyse de la question en cours..."):
                if run_gpt_question(question_input, api_key, gpt_model):
                    answer_result = get_session_value("answer_result", "")
                    set_session_value("last_question", question_input)
                    last_question = question_input
                    st.success("‚úÖ R√©ponse g√©n√©r√©e avec succ√®s!")

        # Affichage du r√©sultat
        if answer_result and last_question:
            # Encadr√© de la question
            st.markdown(f"""
            <div style="background-color:#333; padding:10px; border-radius:5px; margin-bottom:10px">
                <p style="color:white; font-weight:bold;">Question :</p>
                <p style="color:white;">{last_question}</p>
            </div>
            """, unsafe_allow_html=True)

            # Encadr√© de la r√©ponse
            st.markdown(f"""
            <div style="background-color:#1E6FCC; padding:10px; border-radius:5px;">
                <p style="color:white; font-weight:bold;">R√©ponse :</p>
                <p style="color:white;">{answer_result}</p>
            </div>
            """, unsafe_allow_html=True)

            # Historique et nouvelle question
            st.markdown("##### Historique des questions")

            # R√©cup√©rer l'historique des questions/r√©ponses
            qa_history = get_session_value("qa_history", [])

            # V√©rifier si la derni√®re question/r√©ponse est d√©j√† dans l'historique
            current_qa = {"question": last_question, "answer": answer_result}
            if not qa_history or qa_history[-1] != current_qa:
                qa_history.append(current_qa)
                set_session_value("qa_history", qa_history)

            # Afficher l'historique des questions sous forme d'accord√©on
            if qa_history:
                for i, qa in enumerate(qa_history):
                    with st.expander(f"Q: {qa['question'][:50]}..."):
                        st.markdown(f"**Question:** {qa['question']}")
                        st.markdown(f"**R√©ponse:** {qa['answer']}")

    with tabs[4]:  # Onglet Chapitres
        st.subheader("üìë G√©n√©ration de chapitres")

        # V√©rifier si une transcription existe avec segments
        segments = get_session_value("segments", [])
        if not segments:
            st.warning("‚ö†Ô∏è Aucun segment de transcription disponible. Veuillez d'abord effectuer une transcription.")
            return

        # Options de g√©n√©ration de chapitres
        col1, col2 = st.columns([3, 1])

        with col1:
            # R√©glage de la dur√©e des chapitres
            chunk_duration = st.slider(
                "Dur√©e approximative des chapitres (secondes)",
                min_value=30,
                max_value=300,
                value=60,
                step=15,
                help="Dur√©e cible pour chaque chapitre"
            )

            total_duration = segments[-1]["end"] if segments else 0
            estimated_chapters = max(1, int(total_duration / chunk_duration))
            st.caption(f"Estimation: environ {estimated_chapters} chapitres pour {total_duration:.1f} secondes d'audio")

        with col2:
            st.write("")
            st.write("")
            generate_button = st.button(
                "G√©n√©rer les chapitres",
                type="primary",
                use_container_width=True
            )

        # Afficher la barre de s√©paration
        st.divider()

        # R√©sultat existant ou traitement de la g√©n√©ration
        chapters_result = get_session_value("chapters_result", "")

        if generate_button:
            with st.spinner("G√©n√©ration des chapitres en cours..."):
                if create_text_chapters(chunk_duration):
                    chapters_result = get_session_value("chapters_result", "")
                    st.success("‚úÖ Chapitres g√©n√©r√©s avec succ√®s!")

        # Affichage du r√©sultat
        if chapters_result:
            st.subheader("Chapitres g√©n√©r√©s")

            # Traitement des chapitres pour un affichage plus attrayant
            chapters_list = chapters_result.strip().split('\n')

            # Affichage sous forme de chronologie
            for i, chapter in enumerate(chapters_list):
                # Extraction du timecode
                try:
                    time_part = chapter.split("√† ")[1].split(" =>")[0]
                    text_part = chapter.split("=>")[1].strip()

                    # Cr√©ation d'une ligne de temps
                    col1, col2 = st.columns([1, 5])
                    with col1:
                        st.markdown(f"""
                           <div style="background-color:#1E6FCC; color:white; text-align:center; padding:8px; 
                                       border-radius:5px; font-weight:bold;">
                               {time_part}
                           </div>
                           """, unsafe_allow_html=True)
                    with col2:
                        st.markdown(f"""
                           <div style="background-color:#333; color:white; padding:8px; border-radius:5px; 
                                       margin-bottom:5px;">
                               {text_part}
                           </div>
                           """, unsafe_allow_html=True)
                except:
                    # Fallback si le format n'est pas celui attendu
                    st.markdown(chapter)

            # Options pour t√©l√©charger
            st.download_button(
                label="T√©l√©charger les chapitres (TXT)",
                data=chapters_result,
                file_name=f"chapitres_{int(time.time())}.txt",
                mime="text/plain"
            )